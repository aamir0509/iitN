{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Ajay_Kumar_Indoria_Day_3.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VcG0JmgPWIwQ","colab_type":"text"},"source":["**Lab 1**\n","\n","Using the dataset at https://bit.ly/2JIORnq\n","1. Assign it to a variable called users and use the 'user_id' as index\n","2. What is the age with least occurrence?\n","3. What is the mean age of users?\n","4. What is the most frequent occupation?"]},{"cell_type":"code","metadata":{"id":"LheHxlwv9WBx","colab_type":"code","outputId":"ea2f4773-2eee-4a7e-f4f3-94047add4f69","executionInfo":{"status":"ok","timestamp":1573455164411,"user_tz":-330,"elapsed":1239,"user":{"displayName":"AJAY INDORIA","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhQ1oT58rv12R8vifIQGxCNS0ITfFYEnrVCKksIts=s64","userId":"02844301383334640492"}},"colab":{"base_uri":"https://localhost:8080/","height":554}},"source":["import pandas as pd\n","import numpy as np\n","user=pd.read_csv(\"https://bit.ly/2JIORnq\", delimiter='|')\n","print(user)\n","count1 = user['age'].value_counts(ascending=True) \n","#print(count1) \n","print(\"\\n \\n \\n Age with least occurrence\")\n","print(count1.head(1))\n","print('\\n \\n \\n  Mean age of users')\n","print(user.mean())\n","count2 = user['occupation'].value_counts() \n","#print(count2) \n","print('\\n \\n Most frequent occupation')\n","print(count2.head(1))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["     user_id  age gender     occupation zip_code\n","0          1   24      M     technician    85711\n","1          2   53      F          other    94043\n","2          3   23      M         writer    32067\n","3          4   24      M     technician    43537\n","4          5   33      F          other    15213\n","..       ...  ...    ...            ...      ...\n","938      939   26      F        student    33319\n","939      940   32      M  administrator    02215\n","940      941   20      M        student    97229\n","941      942   48      F      librarian    78209\n","942      943   22      M        student    77841\n","\n","[943 rows x 5 columns]\n","\n"," \n"," \n"," Age with least occurrence\n","7    1\n","Name: age, dtype: int64\n","\n"," \n"," \n","  Mean age of users\n","user_id    472.000000\n","age         34.051962\n","dtype: float64\n","\n"," \n"," Most frequent occupation\n","student    196\n","Name: occupation, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v8RGdFIVXEuC","colab_type":"text"},"source":["**Lab 2**\n","\n","Dataset: https://bit.ly/2UUomN0\n","1. What is the price of each item?\n","2. What was the quantity of the most expensive item ordered?\n","3. How many times were a Veggie Salad Bowl ordered?\n","4. How many times people ordered more than one Canned Soda?\n","\n"]},{"cell_type":"code","metadata":{"id":"fEPol84hPfUy","colab_type":"code","outputId":"dffb0ef5-6340-414d-b50b-d4ee9b4cc386","executionInfo":{"status":"ok","timestamp":1573533501586,"user_tz":-330,"elapsed":1096,"user":{"displayName":"AJAY INDORIA","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhQ1oT58rv12R8vifIQGxCNS0ITfFYEnrVCKksIts=s64","userId":"02844301383334640492"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["import pandas as pd\n","import numpy as np\n","user=pd.read_csv(\"https://bit.ly/2UUomN0\", delimiter='\\t')\n","#print(user[['item_name', 'item_price']] )\n","#print(user)\n","#expen = user['item_price'].value_counts() \n","#print('\\n \\n \\n Most expensive item')\n","#print(expen.head(1))\n","#user = user.DataFrame(np.random.random(200).reshape(2, 100))\n","user['item_price']=user['item_price'].map(lambda x: float(x.strip()[1:]))\n","user.sort_values(by=['item_price'],ascending=False)\n","expen = user['item_price'].value_counts() \n","#z=user.sort_values(\"item_price\", ascending=False)\n","print(user)\n","print('\\n \\n \\n Most expensive item')\n","print(expen.head(1))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["      order_id  ...  item_price\n","0            1  ...        2.39\n","1            1  ...        3.39\n","2            1  ...        3.39\n","3            1  ...        2.39\n","4            2  ...       16.98\n","...        ...  ...         ...\n","4617      1833  ...       11.75\n","4618      1833  ...       11.75\n","4619      1834  ...       11.25\n","4620      1834  ...        8.75\n","4621      1834  ...        8.75\n","\n","[4622 rows x 5 columns]\n","\n"," \n"," \n"," Most expensive item\n","8.75    730\n","Name: item_price, dtype: int64\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oVDcfaNph7zo","colab_type":"text"},"source":["**Lab 3**\n","\n","Dataset: https://bit.ly/1N5br3h\n","1. Assign Columns for the dataset \n","2. Is there any missing value in the dataframe?\n","3. delete the column class\n","4. set the values of the rows 10 to 29 of the column 'petal_length' to NaN\n","5. Delete the rows that have NaN\n","6. Reset the index so it begins with 0 again\n","7. BONUS: Create & Answer your own question\n","(Find the Second Most Frequent Element)"]},{"cell_type":"code","metadata":{"id":"r_9iHdtl5_LO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fa9c6245-26be-4523-f17e-222b76932526","executionInfo":{"status":"ok","timestamp":1573536090468,"user_tz":-330,"elapsed":1058,"user":{"displayName":"AJAY INDORIA","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhQ1oT58rv12R8vifIQGxCNS0ITfFYEnrVCKksIts=s64","userId":"02844301383334640492"}}},"source":["import pandas as pd\n","import numpy as np\n","user=pd.read_csv(\"https://bit.ly/1N5br3h\", delimiter=',', names=['sepal_length','sepal_width','petal_length', 'petal_width', 'species'])\n","#user=pd.read_csv(\"https://bit.ly/1N5br3h\", delimiter=',', names=['1','2','3'])\n","print(user)\n","print(\"\\n \\n \\n \\n Total Null Values Searched=\")\n","print(user.isnull().sum().sum())\n","user1=user\n","print(\"\\n \\n \\n Reulting Dataset After Deleting the coloum.........\")\n","user1.drop([\"species\"], axis = 1, inplace = True)\n","print(user1)\n","print(\"\\n \\n \\n Updating the Data from 10 to 29 Row to NAN\")\n","for index in range(10,29): \n","  user1.at[2:5,['petal_length']]=np.NaN\n","print(user1)\n","print(\"\\n \\n \\n \\n Total Null Values Searched=\")\n","print(user1.isnull().sum().sum())\n","print('\\n\\n\\n\\n.........Delete the NaN Rows From Data set.....\\n\\n\\n\\n')\n","user2=user1.dropna()\n","print(user2)\n","print('\\n\\n\\n\\n.........Reset the index so it begins with 0 again.....\\n\\n\\n\\n')\n","user2=user2.reset_index(drop=True)\n","print(user2)\n","#List = user.sepal_l#ength\n","#user['species'].value_counts().argmax()\n","\n","\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["     sepal_length  sepal_width  petal_length  petal_width         species\n","0             5.1          3.5           1.4          0.2     Iris-setosa\n","1             4.9          3.0           1.4          0.2     Iris-setosa\n","2             4.7          3.2           1.3          0.2     Iris-setosa\n","3             4.6          3.1           1.5          0.2     Iris-setosa\n","4             5.0          3.6           1.4          0.2     Iris-setosa\n","..            ...          ...           ...          ...             ...\n","145           6.7          3.0           5.2          2.3  Iris-virginica\n","146           6.3          2.5           5.0          1.9  Iris-virginica\n","147           6.5          3.0           5.2          2.0  Iris-virginica\n","148           6.2          3.4           5.4          2.3  Iris-virginica\n","149           5.9          3.0           5.1          1.8  Iris-virginica\n","\n","[150 rows x 5 columns]\n","\n"," \n"," \n"," \n"," Total Null Values Searched=\n","0\n","\n"," \n"," \n"," Reulting Dataset After Deleting the coloum.........\n","     sepal_length  sepal_width  petal_length  petal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.7          3.2           1.3          0.2\n","3             4.6          3.1           1.5          0.2\n","4             5.0          3.6           1.4          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[150 rows x 4 columns]\n","\n"," \n"," \n"," Updating the Data from 10 to 29 Row to NAN\n","     sepal_length  sepal_width  petal_length  petal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.7          3.2           NaN          0.2\n","3             4.6          3.1           NaN          0.2\n","4             5.0          3.6           NaN          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[150 rows x 4 columns]\n","\n"," \n"," \n"," \n"," Total Null Values Searched=\n","4\n","\n","\n","\n","\n",".........Delete the NaN Rows From Data set.....\n","\n","\n","\n","\n","     sepal_length  sepal_width  petal_length  petal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","6             4.6          3.4           1.4          0.3\n","7             5.0          3.4           1.5          0.2\n","8             4.4          2.9           1.4          0.2\n","..            ...          ...           ...          ...\n","145           6.7          3.0           5.2          2.3\n","146           6.3          2.5           5.0          1.9\n","147           6.5          3.0           5.2          2.0\n","148           6.2          3.4           5.4          2.3\n","149           5.9          3.0           5.1          1.8\n","\n","[146 rows x 4 columns]\n","\n","\n","\n","\n",".........Reset the index so it begins with 0 again.....\n","\n","\n","\n","\n","     sepal_length  sepal_width  petal_length  petal_width\n","0             5.1          3.5           1.4          0.2\n","1             4.9          3.0           1.4          0.2\n","2             4.6          3.4           1.4          0.3\n","3             5.0          3.4           1.5          0.2\n","4             4.4          2.9           1.4          0.2\n","..            ...          ...           ...          ...\n","141           6.7          3.0           5.2          2.3\n","142           6.3          2.5           5.0          1.9\n","143           6.5          3.0           5.2          2.0\n","144           6.2          3.4           5.4          2.3\n","145           5.9          3.0           5.1          1.8\n","\n","[146 rows x 4 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BQLrpMwOOJYN","colab_type":"text"},"source":["**Lab 4**\n","\n","DataSet: https://bit.ly/2CudMVh\n","1. Assign it to a variable called drinks.\n","2. Which continent drinks more beer on average?\n","3. For each continent print the statistics for wine consumption.\n","4. Display the mean alcohol consumption per continent for every column.\n","5. Display the median alcohol consumption per continent for every column.\n","6. Display the mean, min and max values for spirit consumption."]},{"cell_type":"code","metadata":{"id":"3Mv8jRwQD9q7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"a6828b1e-5ed9-4b95-f08e-6f379dd81424","executionInfo":{"status":"ok","timestamp":1573537062616,"user_tz":-330,"elapsed":1457,"user":{"displayName":"AJAY INDORIA","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAhQ1oT58rv12R8vifIQGxCNS0ITfFYEnrVCKksIts=s64","userId":"02844301383334640492"}}},"source":["import pandas as pd\n","drinks = pd.read_csv(\"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/drinks.csv\",sep=',' )\n","print(drinks)\n","drinks=drinks.head(60)\n","print(drinks)\n","more_avg_beer=drinks.groupby('continent').beer_servings.mean()\n","print(more_avg_beer)\n","more_avg_beer=more_avg_beer.head(1)\n","print(more_avg_beer)\n","drinks1=drinks.groupby('continent').wine_servings.mean()\n","print(drinks1)\n","drinks1=drinks.groupby('continent').total_litres_of_pure_alcohol.mean()\n","print(drinks1)\n","drinks1=drinks.groupby('continent').total_litres_of_pure_alcohol.median()\n","print(drinks1)\n","drinks1=drinks.spirit_servings.mean()\n","print(drinks1)\n","drinks1=drinks.spirit_servings.min(axis=0)\n","print(drinks1)\n","drinks1=drinks.spirit_servings.max(axis=0)\n","print(drinks1)"],"execution_count":36,"outputs":[{"output_type":"stream","text":["         country  beer_servings  ...  total_litres_of_pure_alcohol  continent\n","0    Afghanistan              0  ...                           0.0         AS\n","1        Albania             89  ...                           4.9         EU\n","2        Algeria             25  ...                           0.7         AF\n","3        Andorra            245  ...                          12.4         EU\n","4         Angola            217  ...                           5.9         AF\n","..           ...            ...  ...                           ...        ...\n","188    Venezuela            333  ...                           7.7         SA\n","189      Vietnam            111  ...                           2.0         AS\n","190        Yemen              6  ...                           0.1         AS\n","191       Zambia             32  ...                           2.5         AF\n","192     Zimbabwe             64  ...                           4.7         AF\n","\n","[193 rows x 6 columns]\n","                     country  ...  continent\n","0                Afghanistan  ...         AS\n","1                    Albania  ...         EU\n","2                    Algeria  ...         AF\n","3                    Andorra  ...         EU\n","4                     Angola  ...         AF\n","5          Antigua & Barbuda  ...        NaN\n","6                  Argentina  ...         SA\n","7                    Armenia  ...         EU\n","8                  Australia  ...         OC\n","9                    Austria  ...         EU\n","10                Azerbaijan  ...         EU\n","11                   Bahamas  ...        NaN\n","12                   Bahrain  ...         AS\n","13                Bangladesh  ...         AS\n","14                  Barbados  ...        NaN\n","15                   Belarus  ...         EU\n","16                   Belgium  ...         EU\n","17                    Belize  ...        NaN\n","18                     Benin  ...         AF\n","19                    Bhutan  ...         AS\n","20                   Bolivia  ...         SA\n","21        Bosnia-Herzegovina  ...         EU\n","22                  Botswana  ...         AF\n","23                    Brazil  ...         SA\n","24                    Brunei  ...         AS\n","25                  Bulgaria  ...         EU\n","26              Burkina Faso  ...         AF\n","27                   Burundi  ...         AF\n","28             Cote d'Ivoire  ...         AF\n","29                Cabo Verde  ...         AF\n","30                  Cambodia  ...         AS\n","31                  Cameroon  ...         AF\n","32                    Canada  ...        NaN\n","33  Central African Republic  ...         AF\n","34                      Chad  ...         AF\n","35                     Chile  ...         SA\n","36                     China  ...         AS\n","37                  Colombia  ...         SA\n","38                   Comoros  ...         AF\n","39                     Congo  ...         AF\n","40              Cook Islands  ...         OC\n","41                Costa Rica  ...        NaN\n","42                   Croatia  ...         EU\n","43                      Cuba  ...        NaN\n","44                    Cyprus  ...         EU\n","45            Czech Republic  ...         EU\n","46               North Korea  ...         AS\n","47                  DR Congo  ...         AF\n","48                   Denmark  ...         EU\n","49                  Djibouti  ...         AF\n","50                  Dominica  ...        NaN\n","51        Dominican Republic  ...        NaN\n","52                   Ecuador  ...         SA\n","53                     Egypt  ...         AF\n","54               El Salvador  ...        NaN\n","55         Equatorial Guinea  ...         AF\n","56                   Eritrea  ...         AF\n","57                   Estonia  ...         EU\n","58                  Ethiopia  ...         AF\n","59                      Fiji  ...         OC\n","\n","[60 rows x 6 columns]\n","continent\n","AF     62.210526\n","AS     29.000000\n","EU    187.857143\n","OC    112.666667\n","SA    176.000000\n","Name: beer_servings, dtype: float64\n","continent\n","AF    62.210526\n","Name: beer_servings, dtype: float64\n","continent\n","AF     20.578947\n","AS      2.125000\n","EU    126.214286\n","OC     95.666667\n","SA     70.500000\n","Name: wine_servings, dtype: float64\n","continent\n","AF    2.742105\n","AS    1.275000\n","EU    8.714286\n","OC    6.100000\n","SA    5.883333\n","Name: total_litres_of_pure_alcohol, dtype: float64\n","continent\n","AF    1.80\n","AS    0.50\n","EU    9.95\n","OC    5.90\n","SA    5.70\n","Name: total_litres_of_pure_alcohol, dtype: float64\n","82.78333333333333\n","0\n","373\n"],"name":"stdout"}]}]}